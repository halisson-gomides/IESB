{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h7uT5S4e0IrX",
        "eeWbZ_eKC0GB",
        "NNpqDuY6C52V",
        "RLH1u5GPMOnX"
      ],
      "authorship_tag": "ABX9TyOX+KyLWJMPc0QoFydHazZY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"> <font color=\"red\"> ===== Deep Learning - Mini Projeto 01 =====</font></h1>\n",
        "<br>\n",
        "<h5 align=\"right\">Brasília, dezembro de 2022</h5>\n",
        "<br>\n",
        "<b align=\"center\"> Professor: Mateus Mendelson</b>\n",
        "<br><br>\n",
        "<b align=\"center\"> Alunos:</b><br>\n",
        "<b align=\"center\">Halisson Souza Gomides </b><br>\n",
        "<b align=\"center\"> Lorena Vaz</b><br>\n",
        "<b align=\"center\"> Roberto Rodrigues Adrego</b>\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "SLXSjsJUr04V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração de Ambiente e tratamento de dados"
      ],
      "metadata": {
        "id": "oaPTy1Y9_aB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMIpqmx6VeyT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "# random_seed = 123 # >> ACCURACY:  0.8013333333333333\n",
        "random_seed = 10 # >> ACCURACY:  0.8093333333333333\n",
        "# random_seed = 123456\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI8cv2vtVeyW"
      },
      "outputs": [],
      "source": [
        "# Efforts for reproducibility\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-8-GrSBVeyX"
      },
      "outputs": [],
      "source": [
        "path = '/content/df_points.txt'\n",
        "\n",
        "df = pd.read_csv(path, sep='\\t', index_col=[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INvAcJHwVeyY"
      },
      "source": [
        "Quantos registros temos no dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPFJVlIVeya",
        "outputId": "565f6463-6c47-4597-95d1-2cfea4ad2002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dataset possui 10,000.0 registros\n"
          ]
        }
      ],
      "source": [
        "print(f'O dataset possui {df.shape[0]:,.1f} registros')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y1XC2rb-Veyf",
        "outputId": "1f76f766-a474-4972-9cc0-a15b05751761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            x           y           z  label\n",
              "0  326.488285  188.988808 -312.205307    0.0\n",
              "1 -314.287214  307.276723 -179.037412    1.0\n",
              "2 -328.208910  181.627758  446.311062    1.0\n",
              "3 -148.658890  147.027947  -27.477959    1.0\n",
              "4 -467.065931  250.467651 -306.475330    1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d11f336f-8248-4eb2-a02d-2543509ec8aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>326.488285</td>\n",
              "      <td>188.988808</td>\n",
              "      <td>-312.205307</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-314.287214</td>\n",
              "      <td>307.276723</td>\n",
              "      <td>-179.037412</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-328.208910</td>\n",
              "      <td>181.627758</td>\n",
              "      <td>446.311062</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-148.658890</td>\n",
              "      <td>147.027947</td>\n",
              "      <td>-27.477959</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-467.065931</td>\n",
              "      <td>250.467651</td>\n",
              "      <td>-306.475330</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d11f336f-8248-4eb2-a02d-2543509ec8aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d11f336f-8248-4eb2-a02d-2543509ec8aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d11f336f-8248-4eb2-a02d-2543509ec8aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxSoqluRVeyh"
      },
      "source": [
        "Vamos dividir os dados em conjuntos de treinamento, validação e teste nas seguintes proporções:\n",
        "\n",
        "- treinamento: `70%`\n",
        "- validação:   `15%`\n",
        "- teste:       `15%`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrI3Sd1oVeym"
      },
      "outputs": [],
      "source": [
        "train_p = 0.7\n",
        "val_p = 0.15\n",
        "test_p = 0.15\n",
        "\n",
        "train_size = int(train_p*df.shape[0])\n",
        "val_size = int(val_p*df.shape[0])\n",
        "test_size = int(test_p*df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzak109NVeyp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['x', 'y', 'z']],\n",
        "                                                    df['label'],\n",
        "                                                    train_size=train_size,\n",
        "                                                    stratify=df['label'],\n",
        "                                                    random_state=random_seed\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl_VaSbgVeyr"
      },
      "outputs": [],
      "source": [
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,\n",
        "                                                    y_test,\n",
        "                                                    test_size=test_size,\n",
        "                                                    stratify=y_test,\n",
        "                                                    random_state=random_seed\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-00dui-Veys"
      },
      "outputs": [],
      "source": [
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_valid.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDyDCFnOVeyt"
      },
      "source": [
        "Amostras em cada conjunto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XnSRF5FVeyt",
        "outputId": "2bf6ec5b-5174-4839-a40f-eb3062b7e436"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uZJ5r0RVeyu",
        "outputId": "150ad06a-3ac7-4431-e080-32d654a5f2b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OUyVFIeVeyu",
        "outputId": "763e3b52-bd22-4356-8af3-7b77c9557b24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFID2dhCVeyv"
      },
      "source": [
        "Vamos normalizar os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRVAtgJdVeyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ss = StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8bO8IWYVeyw"
      },
      "source": [
        "Note que o `fit` deve ser realizado apenas com o conjunto de treinamento!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb06xIxxVeyx",
        "outputId": "7ce61f76-e35c-46c3-bdf5-6a1880001301"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ss.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8LKiNP_Veyy"
      },
      "outputs": [],
      "source": [
        "X_train = ss.transform(X_train)\n",
        "X_valid = ss.transform(X_valid)\n",
        "X_test = ss.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wnzAXvCVeyz"
      },
      "source": [
        "Como a normalização ficou:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hFx0hFMVeyz",
        "outputId": "8600df76-3f5f-4bff-8af4-b8c0e233b53b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.39601882,  1.45043415,  0.43291041],\n",
              "       [ 1.59359658, -0.88212023,  1.04995899],\n",
              "       [-1.6717337 , -0.43105859,  0.33223992],\n",
              "       ...,\n",
              "       [ 1.24034175, -0.48110015,  1.37646803],\n",
              "       [ 1.58736464,  0.07917989,  0.30736798],\n",
              "       [-0.37117044, -0.8237158 , -0.62861755]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding:"
      ],
      "metadata": {
        "id": "xSruIgUzd5Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.get_dummies(y_train, prefix='target').reset_index(drop=True)\n",
        "y_valid = pd.get_dummies(y_valid, prefix='target').reset_index(drop=True)\n",
        "y_test = pd.get_dummies(y_test, prefix='target').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "IRTlKG_Wd79k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PrDmpQvAd-oR",
        "outputId": "21a6d56d-08af-4481-a997-69711e06fcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target_0.0  target_1.0\n",
              "0              1           0\n",
              "1              1           0\n",
              "2              0           1\n",
              "3              1           0\n",
              "4              1           0\n",
              "...          ...         ...\n",
              "6995           0           1\n",
              "6996           0           1\n",
              "6997           0           1\n",
              "6998           1           0\n",
              "6999           1           0\n",
              "\n",
              "[7000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21d2fc04-4428-40e2-adf4-4d396895205f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_0.0</th>\n",
              "      <th>target_1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21d2fc04-4428-40e2-adf4-4d396895205f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21d2fc04-4428-40e2-adf4-4d396895205f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21d2fc04-4428-40e2-adf4-4d396895205f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-Projeto"
      ],
      "metadata": {
        "id": "rZmaIavw_u_k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuNyQibbVezJ"
      },
      "source": [
        "Aqui, deixamos o primeiro mini-projeto da disciplina: uma competição!\n",
        "\n",
        "Utilize tudo que estiver ao seu alcance para atingir a maior acurácia sobre o conjunto de teste.\n",
        "\n",
        ">Entenda **tudo** como **tudo que é conceitualmente correto**, ou seja, não é permitido o uso do conjunto de teste em nenhum momento além do cálculo da acurácia final."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "7snXAr_QCGh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funções"
      ],
      "metadata": {
        "id": "h7uT5S4e0IrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, X_test, y_test):\n",
        "    model.eval()\n",
        "\n",
        "    hits = 0\n",
        "    for index, (original_data, original_target) in enumerate(zip(X_test, y_test)):\n",
        "        # Format data to tensor\n",
        "        target = original_target\n",
        "        data = torch.tensor(()).new_ones((1, 3))\n",
        "        data[0] = original_data\n",
        "\n",
        "        # GPU\n",
        "        # target = target.cuda()\n",
        "        # data = data.cuda()\n",
        "\n",
        "        # Softmax: https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html\n",
        "        # Probability for each output\n",
        "        predicted = F.softmax(model(data), dim=1)\n",
        "\n",
        "        # The output with the highest probability is the predicted class\n",
        "        # Let's calculate the accuracy\n",
        "        if torch.argmax(predicted[0]) == torch.argmax(target):\n",
        "            hits += 1\n",
        "            \n",
        "    return hits/(index+1)"
      ],
      "metadata": {
        "id": "C1R4hSQ50gHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(data, batch_size=1):\n",
        "    batches = []\n",
        "    \n",
        "    data_size = len(data)\n",
        "    for start_idx in range(0, data_size, batch_size):\n",
        "        end_idx = min(data_size, start_idx + batch_size)\n",
        "        batches.append(data[start_idx:end_idx])\n",
        "    \n",
        "    return batches"
      ],
      "metadata": {
        "id": "66626FFm0Wue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, n_epochs, batch_size, early_stopping_epochs, optimizer, criterion, X_train, y_train, X_valid, y_valid):\n",
        "    init = datetime.now()\n",
        "    \n",
        "    best_epoch = None\n",
        "    best_valid_loss = np.Inf\n",
        "    best_train_loss = None\n",
        "    epochs_without_improv = 0\n",
        "    \n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        ###################\n",
        "        # early stopping? #\n",
        "        ###################\n",
        "        if epochs_without_improv >= early_stopping_epochs:\n",
        "            break\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        acc_train_loss = 0.0\n",
        "        for index, (original_data, original_target) in enumerate(zip(get_batches(X_train, batch_size),\n",
        "                                                                     get_batches(y_train, batch_size))):\n",
        "            \n",
        "            # Format data to tensor\n",
        "            target = (original_target == 1).nonzero(as_tuple=True)[1]\n",
        "            data = original_data.float() # Esse '.float()' é necessário para arrumar o tipo do dado\n",
        "\n",
        "            # target = target.cuda()\n",
        "            # data = data.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # model.forward(data)\n",
        "            predicted = model(data)\n",
        "\n",
        "            loss = criterion(predicted, target)\n",
        "\n",
        "            # Backprop\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            acc_train_loss += loss.item()\n",
        "\n",
        "        train_loss.append(acc_train_loss)\n",
        "\n",
        "        ###################\n",
        "        # valid the model #\n",
        "        ###################\n",
        "        model.eval()\n",
        "        acc_valid_loss = 0.0\n",
        "        for index, (original_data, original_target) in enumerate(zip(get_batches(X_valid, batch_size), \n",
        "                                                                     get_batches(y_valid, batch_size))):\n",
        "            # Format data to tensor\n",
        "            target = (original_target == 1).nonzero(as_tuple=True)[1]\n",
        "            data = original_data.float() # Esse '.float()' é necessário para arrumar o tipo do dado\n",
        "\n",
        "            # target = target.cuda()\n",
        "            # data = data.cuda()\n",
        "\n",
        "            # model.forward(data)\n",
        "            predicted = model(data)\n",
        "\n",
        "            loss = criterion(predicted, target)\n",
        "            acc_valid_loss += loss.item()\n",
        "\n",
        "        valid_loss.append(acc_valid_loss)\n",
        "        \n",
        "        #####################\n",
        "        # Update best model #\n",
        "        #####################\n",
        "        if acc_valid_loss < best_valid_loss:\n",
        "            torch.save(model.state_dict(), 'best_model') # save best model\n",
        "            best_epoch = epoch\n",
        "            best_valid_loss = acc_valid_loss\n",
        "            best_train_loss = acc_train_loss\n",
        "            epochs_without_improv = 0\n",
        "        else:\n",
        "            epochs_without_improv += 1\n",
        "    \n",
        "    \n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load('best_model'))\n",
        "    model.eval()\n",
        "    \n",
        "    # Print logs\n",
        "    if epochs_without_improv >= early_stopping_epochs:\n",
        "        print('Training interrupted by early stopping!')\n",
        "    else:\n",
        "        print('Training finished by epochs!')\n",
        "    print(f'Total epochs run: {epoch + 1}')\n",
        "    print(f'Best model found at epoch {best_epoch + 1} with valid loss {best_valid_loss} and training loss {best_train_loss}')\n",
        "    \n",
        "    end = datetime.now()\n",
        "    print(f'Total training time: {end - init}')\n",
        "    \n",
        "    return model, train_loss, valid_loss"
      ],
      "metadata": {
        "id": "1qUS-idS0KHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TENTATIVA 01"
      ],
      "metadata": {
        "id": "eeWbZ_eKC0GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MinhaRede(nn.Module):\n",
        "    def __init__(self, input_features, p=0.5):\n",
        "        super(MinhaRede, self).__init__()\n",
        "\n",
        "        self.camada_entrada = nn.Linear(input_features, 128)\n",
        "        self.camada_oculta_1 = nn.Linear(128, 64)\n",
        "        self.camada_oculta_2 = nn.Linear(64, 32)\n",
        "        self.camada_saida = nn.Linear(32, 2)\n",
        "        \n",
        "        self.dropout_1 = nn.Dropout(p) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "        self.dropout_2 = nn.Dropout(p) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "\n",
        "    def forward(self, p):\n",
        "        s = F.relu(self.camada_entrada(p))\n",
        "        s = self.dropout_1(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento\n",
        "        s = F.relu(self.camada_oculta_1(s))\n",
        "        s = self.dropout_2(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento\n",
        "        s = F.relu(self.camada_oculta_2(s))\n",
        "        s = self.camada_saida(s)\n",
        "\n",
        "        return s"
      ],
      "metadata": {
        "id": "H6Dd23HJBCOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = 3\n",
        "epochs = 2000\n",
        "batch_size = 20\n",
        "early_stopping_epochs = 70 # quantas épocas sem melhoria serão toleradas antes de parar o treinamento\n",
        "prob_dropout = 0.3\n",
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "NSQPodX7Cytc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeafrTNiVezJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb5f4af-c8a2-4df3-e65d-58e7a07ab1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 306/2000 [01:56<10:43,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 307\n",
            "Best model found at epoch 236 with valid loss 36.698350727558136 and training loss 175.958392187953\n",
            "Total training time: 0:01:56.171156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = MinhaRede(input_features, p=prob_dropout)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model, train_loss, valid_loss = train(model, epochs, batch_size, early_stopping_epochs, optimizer, criterion,\n",
        "                                      torch.from_numpy(X_train),\n",
        "                                      torch.from_numpy(y_train.to_numpy()),\n",
        "                                      torch.from_numpy(X_valid),\n",
        "                                      torch.from_numpy(y_valid.to_numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVjITK1y1rd1",
        "outputId": "9e744c67-2e9e-449c-dc0b-914f7356a673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7826666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TENTATIVA 02"
      ],
      "metadata": {
        "id": "NNpqDuY6C52V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MinhaRede(nn.Module):\n",
        "    def __init__(self, input_features, p=0.5):\n",
        "        super(MinhaRede, self).__init__()\n",
        "\n",
        "        self.camada_entrada = nn.Linear(input_features, 128)\n",
        "        self.camada_oculta_1 = nn.Linear(128, 64)\n",
        "        self.camada_oculta_2 = nn.Linear(64, 32)\n",
        "        self.camada_oculta_3 = nn.Linear(32, 16)\n",
        "        self.camada_saida = nn.Linear(16, 2)\n",
        "        \n",
        "        self.dropout_1 = nn.Dropout(p) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "        self.dropout_2 = nn.Dropout(p) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "\n",
        "    def forward(self, p):\n",
        "        s = F.relu(self.camada_entrada(p))\n",
        "        s = self.dropout_1(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento\n",
        "        s = F.relu(self.camada_oculta_1(s))        \n",
        "        s = F.relu(self.camada_oculta_2(s))\n",
        "        s = self.dropout_2(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento\n",
        "        s = F.relu(self.camada_oculta_3(s))\n",
        "        s = self.camada_saida(s)\n",
        "\n",
        "        return s"
      ],
      "metadata": {
        "id": "AIhIwveUC6_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = 3\n",
        "epochs = 2000\n",
        "batch_size = 20\n",
        "early_stopping_epochs = 70 # quantas épocas sem melhoria serão toleradas antes de parar o treinamento\n",
        "prob_dropout = 0.4\n",
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "Mqk0zd5hJtxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MinhaRede(input_features, p=prob_dropout)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model, train_loss, valid_loss = train(model, epochs, batch_size, early_stopping_epochs, optimizer, criterion,\n",
        "                                      torch.from_numpy(X_train),\n",
        "                                      torch.from_numpy(y_train.to_numpy()),\n",
        "                                      torch.from_numpy(X_valid),\n",
        "                                      torch.from_numpy(y_valid.to_numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsF9JTrSKg5H",
        "outputId": "9bcbaefa-6461-46f7-c46a-370a104b506a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 222/2000 [02:31<20:10,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 223\n",
            "Best model found at epoch 152 with valid loss 37.392108619213104 and training loss 176.56904274225235\n",
            "Total training time: 0:02:31.130150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOwSSGoqxj92",
        "outputId": "8ee42e3c-304e-40ae-a9e6-8e14fdd719ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.792"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = MinhaRede(input_features, p=prob_dropout)\n",
        "best_model.load_state_dict(torch.load('/content/best_model'))\n",
        "\n",
        "acc = get_accuracy(best_model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))\n",
        "print('>> ACCURACY: ', acc, end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWS8KtPRnbbn",
        "outputId": "6484bf70-ca1d-489d-b521-a8716a38d4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> ACCURACY:  0.794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TENTATIVA 03"
      ],
      "metadata": {
        "id": "RLH1u5GPMOnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Arquitetura da rede"
      ],
      "metadata": {
        "id": "WXGH9as5aKHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MinhaRede(nn.Module):\n",
        "    def __init__(self, input_features, p1=0.5, p2=0.5, qtdn=160):\n",
        "        super(MinhaRede, self).__init__()\n",
        "\n",
        "        self.camada_entrada = nn.Linear(input_features, qtdn)\n",
        "        self.camada_oculta_1 = nn.Linear(qtdn, int(qtdn/2))\n",
        "        self.camada_oculta_2 = nn.Linear(int(qtdn/2), int(qtdn/4))\n",
        "        self.camada_oculta_3 = nn.Linear(int(qtdn/4), int(qtdn/8))\n",
        "        self.camada_saida = nn.Linear(int(qtdn/8), 2)\n",
        "        \n",
        "        self.dropout_1 = nn.Dropout(p1) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "        self.dropout_2 = nn.Dropout(p2) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "        # self.dropout_3 = nn.Dropout(p3) # <= criação da camada de dropout, com cada neurônio tendo probabilidade p de ser desativado\n",
        "\n",
        "    def forward(self, p):\n",
        "        s = F.relu(self.camada_entrada(p))\n",
        "        s = self.dropout_1(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento   \n",
        "        s = F.relu(self.camada_oculta_1(s))\n",
        "        s = F.relu(self.camada_oculta_2(s))        \n",
        "        s = self.dropout_2(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento                                    \n",
        "        s = F.relu(self.camada_oculta_3(s))\n",
        "        # s = self.dropout_3(s) # <= aplicamos a camada de dropout, que só faz efeito quando o modelo está em modo de treinamento                        \n",
        "        s = self.camada_saida(s)\n",
        "\n",
        "        return s"
      ],
      "metadata": {
        "id": "Bpx2omF8MQL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Espaço de busca de melhores parâmetros"
      ],
      "metadata": {
        "id": "CUmgkgVTaO3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = 3\n",
        "epochs = 2000\n",
        "\n",
        "batch_sizes = np.array([15, 20, 25, 30])\n",
        "early_stopping_epochs = 100 # quantas épocas sem melhoria serão toleradas antes de parar o treinamento\n",
        "probs_1 = np.array([.15, .2, .3, .35, .4, .5, .55, .6, .65])\n",
        "probs_2 = np.array([.15, .2, .3, .35, .4, .5, .55, .6, .65])\n",
        "qtdns = np.array([96, 112, 128, 144, 160])\n",
        "learning_rates = np.array([1e-3, 1e-4, 1e-5])\n",
        "\n",
        "tentativas = 5"
      ],
      "metadata": {
        "id": "WEhL0M58MlvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Treinamento da rede"
      ],
      "metadata": {
        "id": "acZMavxLaUZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "for _ in range(tentativas):\n",
        "\n",
        "  print('='*100)\n",
        "  learning_rate = np.random.choice(learning_rates)\n",
        "  neuronios = np.random.choice(qtdns)\n",
        "  prob_dropout1 = np.random.choice(probs_1) \n",
        "  prob_dropout2 = np.random.choice(probs_2)\n",
        "  batch_size = np.random.choice(batch_sizes)\n",
        "\n",
        "  # batch_size = 30\n",
        "  # learning_rate = 0.001\n",
        "  # neuronios = 144\n",
        "  # prob_dropout1 = 0.55\n",
        "  # prob_dropout2 = 0.15\n",
        "\n",
        "  print('batch_size: ', batch_size)\n",
        "  print('Learning_rate: ', learning_rate)\n",
        "  print('Qtd. Neuronios out 1: ', neuronios)\n",
        "  print('prob_dropout1: ', prob_dropout1)\n",
        "  print('prob_dropout2: ', prob_dropout2)\n",
        "\n",
        "  model = MinhaRede(input_features, p1=prob_dropout1, p2=prob_dropout2, qtdn=neuronios)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  model, train_loss, valid_loss = train(model, epochs, batch_size, early_stopping_epochs, optimizer, criterion,\n",
        "                                        torch.from_numpy(X_train),\n",
        "                                        torch.from_numpy(y_train.to_numpy()),\n",
        "                                        torch.from_numpy(X_valid),\n",
        "                                        torch.from_numpy(y_valid.to_numpy()))\n",
        "\n",
        "  acc = get_accuracy(model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))\n",
        "  print('>> ACCURACY: ', acc, end='\\n\\n')\n",
        "  \n",
        "  if acc > best_acc:\n",
        "    torch.save(model, 'best_model_tentativa03.pyt')\n",
        "    d_best_model_params = {\n",
        "      'batch_size': batch_size,\n",
        "      'learning_rate': learning_rate,\n",
        "      'neuronios': neuronios,\n",
        "      'prob_dropout1': prob_dropout1,\n",
        "      'prob_dropout2': prob_dropout2\n",
        "    }\n",
        "\n",
        "    with open('/content/best_model_tentativa03_params.pkl', 'wb') as handle:\n",
        "      pickle.dump(d_best_model_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    best_acc = acc\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKPOTCI2Momz",
        "outputId": "c6a4f733-7a72-4ec7-c3e0-02e71d9873b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "batch_size:  15\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  112\n",
            "prob_dropout1:  0.4\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 195/2000 [02:27<22:44,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 196\n",
            "Best model found at epoch 95 with valid loss 50.099229991436005 and training loss 237.20309409499168\n",
            "Total training time: 0:02:27.376148\n",
            ">> ACCURACY:  0.804\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  15\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  160\n",
            "prob_dropout1:  0.6\n",
            "prob_dropout2:  0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 383/2000 [05:55<25:01,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 384\n",
            "Best model found at epoch 283 with valid loss 49.90789234638214 and training loss 238.57456946372986\n",
            "Total training time: 0:05:55.542448\n",
            ">> ACCURACY:  0.804\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  15\n",
            "Learning_rate:  1e-05\n",
            "Qtd. Neuronios out 1:  160\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [24:51<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished by epochs!\n",
            "Total epochs run: 2000\n",
            "Best model found at epoch 1998 with valid loss 50.655465722084045 and training loss 242.5771330446005\n",
            "Total training time: 0:24:51.290920\n",
            ">> ACCURACY:  0.8046666666666666\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  20\n",
            "Learning_rate:  0.0001\n",
            "Qtd. Neuronios out 1:  96\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 759/2000 [06:48<11:07,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 760\n",
            "Best model found at epoch 659 with valid loss 37.40077401697636 and training loss 181.04937963187695\n",
            "Total training time: 0:06:48.026791\n",
            ">> ACCURACY:  0.808\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  25\n",
            "Learning_rate:  1e-05\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.15\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 1296/2000 [09:52<05:22,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 1297\n",
            "Best model found at epoch 1196 with valid loss 30.70126649737358 and training loss 144.46154701709747\n",
            "Total training time: 0:09:52.845968\n",
            ">> ACCURACY:  0.7973333333333333\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "APÓS RESET DO KERNEL, RODANDO COM OS PARÂMETROS DO MELHOR MODELO:"
      ],
      "metadata": {
        "id": "5YgPkaSGVg9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "for _ in range(tentativas):\n",
        "\n",
        "  print('='*100)\n",
        "  # learning_rate = np.random.choice(learning_rates)\n",
        "  # neuronios = np.random.choice(qtdns)\n",
        "  # prob_dropout1 = np.random.choice(probs_1) \n",
        "  # prob_dropout2 = np.random.choice(probs_2)\n",
        "  # batch_size = np.random.choice(batch_sizes)\n",
        "\n",
        "  batch_size = 30\n",
        "  learning_rate = 0.001\n",
        "  neuronios = 144\n",
        "  prob_dropout1 = 0.55\n",
        "  prob_dropout2 = 0.15\n",
        "\n",
        "  print('batch_size: ', batch_size)\n",
        "  print('Learning_rate: ', learning_rate)\n",
        "  print('Qtd. Neuronios out 1: ', neuronios)\n",
        "  print('prob_dropout1: ', prob_dropout1)\n",
        "  print('prob_dropout2: ', prob_dropout2)\n",
        "\n",
        "  model = MinhaRede(input_features, p1=prob_dropout1, p2=prob_dropout2, qtdn=neuronios)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  model, train_loss, valid_loss = train(model, epochs, batch_size, early_stopping_epochs, optimizer, criterion,\n",
        "                                        torch.from_numpy(X_train),\n",
        "                                        torch.from_numpy(y_train.to_numpy()),\n",
        "                                        torch.from_numpy(X_valid),\n",
        "                                        torch.from_numpy(y_valid.to_numpy()))\n",
        "\n",
        "  acc = get_accuracy(model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))\n",
        "  print('>> ACCURACY: ', acc, end='\\n\\n')\n",
        "  \n",
        "  if acc > best_acc:\n",
        "    torch.save(model, 'best_model_tentativa03.pyt')\n",
        "    d_best_model_params = {\n",
        "      'batch_size': batch_size,\n",
        "      'learning_rate': learning_rate,\n",
        "      'neuronios': neuronios,\n",
        "      'prob_dropout1': prob_dropout1,\n",
        "      'prob_dropout2': prob_dropout2\n",
        "    }\n",
        "\n",
        "    with open('/content/best_model_tentativa03_params.pkl', 'wb') as handle:\n",
        "      pickle.dump(d_best_model_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    best_acc = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B71JNXUSOxPp",
        "outputId": "cf5cc17d-d2a8-485a-dfab-d6cb5bb7dd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "batch_size:  30\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 215/2000 [01:26<11:59,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 216\n",
            "Best model found at epoch 115 with valid loss 25.109973430633545 and training loss 121.03501638770103\n",
            "Total training time: 0:01:26.636983\n",
            ">> ACCURACY:  0.802\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  30\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 244/2000 [01:40<12:05,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 245\n",
            "Best model found at epoch 144 with valid loss 24.958782017230988 and training loss 120.01877626776695\n",
            "Total training time: 0:01:40.767192\n",
            ">> ACCURACY:  0.802\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  30\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 269/2000 [01:47<11:32,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 270\n",
            "Best model found at epoch 169 with valid loss 24.914406418800354 and training loss 118.42115581035614\n",
            "Total training time: 0:01:47.647302\n",
            ">> ACCURACY:  0.7993333333333333\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  30\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 225/2000 [01:30<11:50,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 226\n",
            "Best model found at epoch 125 with valid loss 24.96848550438881 and training loss 120.47225534915924\n",
            "Total training time: 0:01:30.086625\n",
            ">> ACCURACY:  0.8066666666666666\n",
            "\n",
            "====================================================================================================\n",
            "batch_size:  30\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 276/2000 [01:51<11:33,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 277\n",
            "Best model found at epoch 176 with valid loss 25.02282229065895 and training loss 119.68830814957619\n",
            "Total training time: 0:01:51.077467\n",
            ">> ACCURACY:  0.804\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTE DO MELHOR MODELO SALVO, APLICADO AOS DADOS COM MESMA RANDOM SEED = 10"
      ],
      "metadata": {
        "id": "xFBHJ4phY3eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "best_model = torch.load('/content/best_model_tentativa03_0_809.pyt')\n",
        "\n",
        "acc = get_accuracy(best_model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))\n",
        "print('>> ACCURACY: ', acc, end='\\n\\n')\n",
        "\n",
        "with open('/content/best_model_tentativa03_0_809_params.pkl', 'rb') as handle:\n",
        "  best_model_params = pickle.load(handle)\n",
        "print('Parâmetros:')\n",
        "print(best_model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7RPLUrUZIT_",
        "outputId": "f08d8c55-8043-4d04-a3ff-05b4ae439a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> ACCURACY:  0.8093333333333333\n",
            "\n",
            "Parâmetros:\n",
            "{'batch_size': 30, 'learning_rate': 0.001, 'neuronios': 144, 'prob_dropout1': 0.55, 'prob_dropout2': 0.15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('='*100)\n",
        "\n",
        "batch_size, learning_rate, neuronios, prob_dropout1, prob_dropout2 = best_model_params.values()\n",
        "print('batch_size: ', batch_size)\n",
        "print('Learning_rate: ', learning_rate)\n",
        "print('Qtd. Neuronios out 1: ', neuronios)\n",
        "print('prob_dropout1: ', prob_dropout1)\n",
        "print('prob_dropout2: ', prob_dropout2)\n",
        "\n",
        "model = MinhaRede(input_features, p1=prob_dropout1, p2=prob_dropout2, qtdn=neuronios)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model, train_loss, valid_loss = train(model, epochs, batch_size, early_stopping_epochs, optimizer, criterion,\n",
        "                                      torch.from_numpy(X_train),\n",
        "                                      torch.from_numpy(y_train.to_numpy()),\n",
        "                                      torch.from_numpy(X_valid),\n",
        "                                      torch.from_numpy(y_valid.to_numpy()))\n",
        "\n",
        "acc = get_accuracy(model,\n",
        "          torch.from_numpy(X_test),\n",
        "          torch.from_numpy(y_test.to_numpy()))\n",
        "print('>> ACCURACY: ', acc, end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZpiDAz-UHm_",
        "outputId": "716616b1-b34f-4922-caa3-d13348f026f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "batch_size:  30\n",
            "Learning_rate:  0.001\n",
            "Qtd. Neuronios out 1:  144\n",
            "prob_dropout1:  0.55\n",
            "prob_dropout2:  0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 302/2000 [02:03<11:36,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 303\n",
            "Best model found at epoch 202 with valid loss 24.931107580661774 and training loss 119.02289918065071\n",
            "Total training time: 0:02:03.975549\n",
            ">> ACCURACY:  0.8066666666666666\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Como pôde ser visto, não foi possível alcançar a mesma acurácia de outrora."
      ],
      "metadata": {
        "id": "imQJZIS6Yl0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TENTATIVA 04"
      ],
      "metadata": {
        "id": "g8iJX7QHT2vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837"
      ],
      "metadata": {
        "id": "8UiR4oHod5mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "ziknvwHURdoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Build a model by implementing define-by-run design from Optuna\n",
        "def build_model_custom(trial):\n",
        "    \n",
        "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
        "    layers = []\n",
        "\n",
        "    in_features = 3\n",
        "    \n",
        "    for i in range(n_layers):\n",
        "                \n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), int(90/(i+1)), int(300/(i+1)))\n",
        "        p_dropout = trial.suggest_float(\"p1\", 0.1, 0.65, step=0.05)\n",
        "\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.LeakyReLU())\n",
        "        layers.append(nn.Dropout(p_dropout))\n",
        "\n",
        "        in_features = out_features        \n",
        "        \n",
        "    layers.append(nn.Linear(in_features, 2))\n",
        "    layers.append(nn.LeakyReLU())\n",
        "    \n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "ldatemktT0Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optuna_train(model, trial, n_epochs, param, X_train, y_train, X_valid, y_valid):\n",
        "\n",
        "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
        "    batch_size = param['batch_size']\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    init = datetime.now()\n",
        "    \n",
        "    best_epoch = None\n",
        "    best_valid_loss = np.Inf\n",
        "    best_train_loss = None\n",
        "    epochs_without_improv = 0\n",
        "    \n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        ###################\n",
        "        # early stopping? #\n",
        "        ###################\n",
        "        if epochs_without_improv >= param['early_stopping_epochs']:\n",
        "            break\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        total_acc_train = 0.0\n",
        "        total_loss_train = 0.0\n",
        "        for index, (original_data, original_target) in enumerate(zip(get_batches(X_train, param['batch_size']),\n",
        "                                                                     get_batches(y_train, param['batch_size']))):\n",
        "            \n",
        "            # Format data to tensor\n",
        "            target = (original_target == 1).nonzero(as_tuple=True)[1]\n",
        "            data = original_data.float() # Esse '.float()' é necessário para arrumar o tipo do dado\n",
        "\n",
        "            # target = target.cuda()\n",
        "            # data = data.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # model.forward(data)\n",
        "            predicted = model(data)\n",
        "\n",
        "            loss = criterion(predicted, target)\n",
        "            total_loss_train  += loss.item()\n",
        "\n",
        "            acc = (predicted.argmax(dim=1) == target).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            # Backprop\n",
        "            loss.backward()\n",
        "            optimizer.step()            \n",
        "\n",
        "        train_loss.append(total_loss_train)\n",
        "\n",
        "        ###################\n",
        "        # valid the model #\n",
        "        ###################\n",
        "        model.eval()\n",
        "        total_acc_valid = 0.0\n",
        "        total_loss_valid = 0.0\n",
        "        for index, (original_data, original_target) in enumerate(zip(get_batches(X_valid, param['batch_size']), \n",
        "                                                                     get_batches(y_valid, param['batch_size']))):\n",
        "            # Format data to tensor\n",
        "            target = (original_target == 1).nonzero(as_tuple=True)[1]\n",
        "            data = original_data.float() # Esse '.float()' é necessário para arrumar o tipo do dado\n",
        "\n",
        "            # target = target.cuda()\n",
        "            # data = data.cuda()\n",
        "\n",
        "            # model.forward(data)\n",
        "            predicted = model(data)\n",
        "\n",
        "            loss = criterion(predicted, target)\n",
        "            total_loss_valid += loss.item()\n",
        "\n",
        "            acc = (predicted.argmax(dim=1) == target).sum().item()\n",
        "            total_acc_valid += acc\n",
        "\n",
        "        valid_loss.append(total_loss_valid)\n",
        "        accuracy = total_acc_valid/len(X_valid)\n",
        "        \n",
        "        # Add prune mechanism\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "          raise optuna.exceptions.TrialPruned()\n",
        "        \n",
        "        #####################\n",
        "        # Update best model #\n",
        "        #####################\n",
        "        if total_loss_valid < best_valid_loss:\n",
        "            # torch.save(model.state_dict(), 'best_model') # save best model\n",
        "            best_epoch = epoch\n",
        "            best_valid_loss = total_loss_valid\n",
        "            best_train_loss = total_loss_train\n",
        "            epochs_without_improv = 0\n",
        "        else:\n",
        "            epochs_without_improv += 1\n",
        "    \n",
        "    \n",
        "    # Load best model\n",
        "    # model.load_state_dict(torch.load('best_model'))\n",
        "    # model.eval()\n",
        "    \n",
        "    # Print logs\n",
        "    if epochs_without_improv >= param['early_stopping_epochs']:\n",
        "        print('Training interrupted by early stopping!')\n",
        "    else:\n",
        "        print('Training finished by epochs!')\n",
        "    print(f'Total epochs run: {epoch + 1}')\n",
        "    print(f'Best model found at epoch {best_epoch + 1} with valid loss {best_valid_loss} and training loss {best_train_loss}')\n",
        "    \n",
        "    end = datetime.now()\n",
        "    print(f'Total training time: {end - init}')\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "YTnEKCMMXmVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2000"
      ],
      "metadata": {
        "id": "C6AVgJZzVWK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def objective(trial): \n",
        "\n",
        "  params = {\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
        "            'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),              \n",
        "            'batch_size': trial.suggest_int(\"batch_size\", 15, 40, step=5),\n",
        "            'early_stopping_epochs': trial.suggest_int(\"early_stopping_epochs\", 70, 120, step=10),\n",
        "            }\n",
        "    \n",
        "  model = build_model_custom(trial)\n",
        "  \n",
        "  accuracy = optuna_train(model, trial, epochs, params, \n",
        "                    torch.from_numpy(X_train),\n",
        "                    torch.from_numpy(y_train.to_numpy()),\n",
        "                    torch.from_numpy(X_valid),\n",
        "                    torch.from_numpy(y_valid.to_numpy()))\n",
        "  \n",
        "  # Save a trained model to a file.\n",
        "  with open(\"/content/optuna_model_{}.pickle\".format(trial.number), \"wb\") as fout:\n",
        "      pickle.dump(model, fout)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "cygw5TKpUO7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "is2m3BxKJ3fW",
        "outputId": "b094a503-825a-4d8b-d929-29685cae4235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-26 14:22:01,451]\u001b[0m A new study created in memory with name: no-name-834432c7-6e91-4968-9a15-bbd3f4a80793\u001b[0m\n",
            "100%|██████████| 2000/2000 [05:32<00:00,  6.02it/s]\n",
            "\u001b[32m[I 2022-11-26 14:27:33,902]\u001b[0m Trial 0 finished with value: 0.578 and parameters: {'learning_rate': 0.00014610870376987413, 'optimizer': 'SGD', 'batch_size': 40, 'early_stopping_epochs': 90, 'n_layers': 2, 'n_units_l0': 146, 'p1': 0.15000000000000002, 'n_units_l1': 73}. Best is trial 0 with value: 0.578.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished by epochs!\n",
            "Total epochs run: 2000\n",
            "Best model found at epoch 2000 with valid loss 23.418964505195618 and training loss 107.8265009522438\n",
            "Total training time: 0:05:32.417048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 491/2000 [03:51<11:50,  2.13it/s]\n",
            "\u001b[32m[I 2022-11-26 14:31:24,951]\u001b[0m Trial 1 finished with value: 0.7846666666666666 and parameters: {'learning_rate': 0.0003307296196279348, 'optimizer': 'RMSprop', 'batch_size': 25, 'early_stopping_epochs': 70, 'n_layers': 5, 'n_units_l0': 268, 'p1': 0.55, 'n_units_l1': 63, 'n_units_l2': 78, 'n_units_l3': 59, 'n_units_l4': 21}. Best is trial 1 with value: 0.7846666666666666.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 492\n",
            "Best model found at epoch 421 with valid loss 30.86790081858635 and training loss 147.23315313458443\n",
            "Total training time: 0:03:51.032679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 537/2000 [08:04<21:58,  1.11it/s]\n",
            "\u001b[32m[I 2022-11-26 14:39:29,099]\u001b[0m Trial 2 finished with value: 0.7846666666666666 and parameters: {'learning_rate': 0.0001315466391572841, 'optimizer': 'Adam', 'batch_size': 15, 'early_stopping_epochs': 100, 'n_layers': 5, 'n_units_l0': 103, 'p1': 0.45000000000000007, 'n_units_l1': 92, 'n_units_l2': 92, 'n_units_l3': 39, 'n_units_l4': 20}. Best is trial 1 with value: 0.7846666666666666.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 538\n",
            "Best model found at epoch 437 with valid loss 51.5263444930315 and training loss 242.33654835820198\n",
            "Total training time: 0:08:04.125611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 721/2000 [02:02<03:38,  5.87it/s]\n",
            "\u001b[32m[I 2022-11-26 14:41:32,015]\u001b[0m Trial 3 finished with value: 0.7666666666666667 and parameters: {'learning_rate': 0.006856916379444076, 'optimizer': 'SGD', 'batch_size': 35, 'early_stopping_epochs': 70, 'n_layers': 2, 'n_units_l0': 92, 'p1': 0.55, 'n_units_l1': 71}. Best is trial 1 with value: 0.7846666666666666.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 722\n",
            "Best model found at epoch 651 with valid loss 23.636359602212906 and training loss 112.50871747732162\n",
            "Total training time: 0:02:02.902761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [09:01<00:00,  3.70it/s]\n",
            "\u001b[32m[I 2022-11-26 14:50:33,201]\u001b[0m Trial 4 finished with value: 0.5833333333333334 and parameters: {'learning_rate': 0.00011773032111817194, 'optimizer': 'SGD', 'batch_size': 40, 'early_stopping_epochs': 110, 'n_layers': 5, 'n_units_l0': 178, 'p1': 0.35, 'n_units_l1': 116, 'n_units_l2': 100, 'n_units_l3': 40, 'n_units_l4': 33}. Best is trial 1 with value: 0.7846666666666666.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished by epochs!\n",
            "Total epochs run: 2000\n",
            "Best model found at epoch 2000 with valid loss 26.295251607894897 and training loss 121.10397201776505\n",
            "Total training time: 0:09:01.159694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 183/2000 [02:39<26:25,  1.15it/s]\n",
            "\u001b[32m[I 2022-11-26 14:53:12,925]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "  2%|▎         | 50/2000 [00:22<14:54,  2.18it/s]\n",
            "\u001b[32m[I 2022-11-26 14:53:35,888]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "  9%|▉         | 188/2000 [01:49<17:36,  1.71it/s]\n",
            "\u001b[32m[I 2022-11-26 14:55:25,584]\u001b[0m Trial 7 finished with value: 0.784 and parameters: {'learning_rate': 0.0023554557899657367, 'optimizer': 'RMSprop', 'batch_size': 20, 'early_stopping_epochs': 100, 'n_layers': 5, 'n_units_l0': 184, 'p1': 0.25, 'n_units_l1': 109, 'n_units_l2': 43, 'n_units_l3': 61, 'n_units_l4': 47}. Best is trial 1 with value: 0.7846666666666666.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training interrupted by early stopping!\n",
            "Total epochs run: 189\n",
            "Best model found at epoch 88 with valid loss 38.36430397629738 and training loss 180.93460568785667\n",
            "Total training time: 0:01:49.674469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2000 [00:00<?, ?it/s]\n",
            "\u001b[32m[I 2022-11-26 14:55:25,793]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "  0%|          | 0/2000 [00:00<?, ?it/s]\n",
            "\u001b[32m[I 2022-11-26 14:55:26,583]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "  7%|▋         | 144/2000 [00:48<10:31,  2.94it/s]\n",
            "\u001b[33m[W 2022-11-26 14:56:15,608]\u001b[0m Trial 10 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-27-22d5db7007a2>\", line 18, in objective\n",
            "    torch.from_numpy(y_valid.to_numpy()))\n",
            "  File \"<ipython-input-25-931907107683>\", line 43, in optuna_train\n",
            "    predicted = model(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-fb532f209430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-22d5db7007a2>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     torch.from_numpy(y_valid.to_numpy()))\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Save a trained model to a file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-931907107683>\u001b[0m in \u001b[0;36moptuna_train\u001b[0;34m(model, trial, n_epochs, param, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# model.forward(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgAHoGQ2L-3j",
        "outputId": "55e98a12-523d-49a1-f6dd-608eca60a75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate: 0.0003307296196279348\n",
            "optimizer: RMSprop\n",
            "batch_size: 25\n",
            "early_stopping_epochs: 70\n",
            "n_layers: 5\n",
            "n_units_l0: 268\n",
            "p1: 0.55\n",
            "n_units_l1: 63\n",
            "n_units_l2: 78\n",
            "n_units_l3: 59\n",
            "n_units_l4: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf1cydBAY-PD",
        "outputId": "9b413c79-cb57-4a61-b3c9-04361aad936b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7846666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "eUi1WcTkRGjV",
        "outputId": "d1ee3f73-9e48-404f-a1af-057dfaa6f1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ff2afa0d-6bd5-45f1-97d7-6d0d436455cf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff2afa0d-6bd5-45f1-97d7-6d0d436455cf\")) {                    Plotly.newPlot(                        \"ff2afa0d-6bd5-45f1-97d7-6d0d436455cf\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,9,10,14,31,32,33],\"y\":[0.7933333333333333,0.7926666666666666,0.78,0.4846666666666667,0.7933333333333333,0.7926666666666666,0.7926666666666666,0.7966666666666666,0.798,0.7946666666666666,0.7926666666666666,0.7926666666666666,0.7906666666666666],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,9,10,14,31,32,33],\"y\":[0.7933333333333333,0.7933333333333333,0.7933333333333333,0.7933333333333333,0.7933333333333333,0.7933333333333333,0.7933333333333333,0.7966666666666666,0.798,0.798,0.798,0.798,0.798],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ff2afa0d-6bd5-45f1-97d7-6d0d436455cf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model.\n",
        "with open(\"/content/optuna_model_{}.pickle\".format(best_trial.number), \"rb\") as fin:\n",
        "    best_model = pickle.load(fin)\n",
        "\n",
        "acc = get_accuracy(best_model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))\n",
        "print('>> ACCURACY: ', acc, end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrELIUSzg_6p",
        "outputId": "2b75b184-3d5b-44f0-9dbe-387ad88c73e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> ACCURACY:  0.8046666666666666\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial.number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVa_ZwLCyCV6",
        "outputId": "317681f5-132a-4397-d7a7-047ce16a62ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'/content/optuna_model_{best_trial.number}_params.pickle', 'wb') as handle:\n",
        "    pickle.dump(best_trial.params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ZC0uENiPcgLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTANDO APÓS RESET DO KERNEL"
      ],
      "metadata": {
        "id": "H1sac5t1AHvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open(\"/content/optuna_model_{}.pickle\".format(2), \"rb\") as fin:\n",
        "    best_model = pickle.load(fin)\n",
        "\n",
        "acc = get_accuracy(best_model,\n",
        "            torch.from_numpy(X_test),\n",
        "            torch.from_numpy(y_test.to_numpy()))\n",
        "print('>> ACCURACY: ', acc, end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhtazerC_4If",
        "outputId": "e91e0bdf-aecf-47b8-9b4b-9942c7e1b50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> ACCURACY:  0.8013333333333333\n",
            "\n"
          ]
        }
      ]
    }
  ]
}